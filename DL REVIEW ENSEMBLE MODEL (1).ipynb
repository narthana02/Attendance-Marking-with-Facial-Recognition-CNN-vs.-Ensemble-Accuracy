{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8758b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 5s 541ms/step - loss: 3.1553 - accuracy: 0.2025 - val_loss: 2.0074 - val_accuracy: 0.7667\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 4s 486ms/step - loss: 1.5746 - accuracy: 0.7173 - val_loss: 1.0190 - val_accuracy: 0.8667\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 4s 474ms/step - loss: 0.9197 - accuracy: 0.8819 - val_loss: 0.8051 - val_accuracy: 0.7667\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 4s 487ms/step - loss: 0.5899 - accuracy: 0.8861 - val_loss: 0.5497 - val_accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 4s 537ms/step - loss: 0.4232 - accuracy: 0.9114 - val_loss: 0.4456 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 4s 553ms/step - loss: 0.2874 - accuracy: 0.9283 - val_loss: 0.4594 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 4s 524ms/step - loss: 0.2164 - accuracy: 0.9494 - val_loss: 0.4634 - val_accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 4s 526ms/step - loss: 0.1539 - accuracy: 0.9662 - val_loss: 0.5358 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 4s 444ms/step - loss: 0.0961 - accuracy: 0.9873 - val_loss: 0.6407 - val_accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 4s 455ms/step - loss: 0.0660 - accuracy: 0.9873 - val_loss: 0.7188 - val_accuracy: 0.9500\n",
      "Choose an option: 1 - Register a new face, 2 - Mark attendance, 3 - Quit: 2\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Attendance already marked for: narthana\n",
      "Choose an option: 1 - Register a new face, 2 - Mark attendance, 3 - Quit: 3\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import cv2  # OpenCV library for computer vision tasks\n",
    "import numpy as np  # NumPy library for numerical operations\n",
    "import os  # OS library for interacting with the operating system\n",
    "import pandas as pd  # Pandas library for data manipulation and analysis\n",
    "from datetime import datetime  # datetime module for working with dates and times\n",
    "from sklearn.model_selection import train_test_split  # Function for splitting data into training and testing sets\n",
    "from sklearn.svm import SVC  # SVM for ensemble\n",
    "from tensorflow.keras.models import Sequential  # Keras Sequential model for building neural networks\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense  # Keras layers for building convolutional neural networks\n",
    "\n",
    "# Function to load images and labels from dataset folder\n",
    "def load_dataset(dataset_path):\n",
    "    images = []  # List to store images\n",
    "    labels = []  # List to store labels\n",
    "    label_names = {}  # Dictionary to store label names\n",
    "\n",
    "    for label, name in enumerate(os.listdir(dataset_path)):  # Iterate over folders in the dataset path\n",
    "        label_names[label] = name  # Store label name in the dictionary\n",
    "        for image_name in os.listdir(os.path.join(dataset_path, name)):  # Iterate over images in each folder\n",
    "            image = cv2.imread(os.path.join(dataset_path, name, image_name), cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "            if image is not None:  # Check if the image was loaded successfully\n",
    "                image = cv2.resize(image, (128, 128))  # Resize the image to 128x128 pixels\n",
    "                images.append(image)  # Add the image to the list\n",
    "                labels.append(label)  # Add the label to the list\n",
    "\n",
    "    return np.array(images), np.array(labels), label_names  # Return images, labels, and label names\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"C:\\\\Users\\\\Narthana\\\\Downloads\\\\images\"  # Path to the dataset folder\n",
    "images, labels, label_names = load_dataset(dataset_path)  # Load the dataset\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)  # Split data into training and testing sets\n",
    "\n",
    "# Reshape images\n",
    "X_train = X_train.reshape(-1, 128, 128, 1)  # Reshape training images for CNN input\n",
    "X_test = X_test.reshape(-1, 128, 128, 1)  # Reshape testing images for CNN input\n",
    "\n",
    "# Normalize images\n",
    "X_train = X_train / 255.0  # Normalize training images to [0, 1] range\n",
    "X_test = X_test / 255.0  # Normalize testing images to [0, 1] range\n",
    "\n",
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),  # Convolutional layer with 32 filters and 3x3 kernel\n",
    "    MaxPooling2D(2, 2),  # Max pooling layer with 2x2 pool size\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # Convolutional layer with 64 filters and 3x3 kernel\n",
    "    MaxPooling2D(2, 2),  # Max pooling layer with 2x2 pool size\n",
    "    Flatten(),  # Flatten layer to convert 2D feature maps to 1D feature vector\n",
    "    Dense(128, activation='relu'),  # Fully connected layer with 128 units and ReLU activation\n",
    "    Dense(len(label_names), activation='softmax')  # Output layer with units equal to the number of classes and softmax activation\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile the model with optimizers and loss function\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))  # Train the model on the training data and validate on the testing data\n",
    "\n",
    "# Define and train SVM model for ensemble\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_flat, y_train)\n",
    "\n",
    "# Function to register new faces\n",
    "def register_face():\n",
    "    name = input(\"Enter name to register: \")  # Prompt the user to enter a name\n",
    "    if not os.path.exists(os.path.join(dataset_path, name)):  # Check if the folder for the name exists\n",
    "        os.makedirs(os.path.join(dataset_path, name))  # Create a new folder for the name\n",
    "    cap = cv2.VideoCapture(0)  # Initialize the webcam\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')  # Load the pre-trained face detection classifier\n",
    "    image_count = 0  # Initialize the image count\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Read a frame from the webcam\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert the frame to grayscale\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))  # Detect faces in the frame\n",
    "        for (x, y, w, h) in faces:  # Iterate over the detected faces\n",
    "            image_count += 1  # Increment the image count\n",
    "            cv2.imwrite(os.path.join(dataset_path, name, f\"{name}_{image_count}.jpg\"), gray[y:y+h, x:x+w])  # Save the face image with the name and count\n",
    "            print(f\"Image {image_count} captured.\")  # Print a message indicating the image capture\n",
    "            if image_count >= 30:  # Check if 30 images have been captured\n",
    "                print(\"Registration successful!\")  # Print a success message\n",
    "                break  # Break out of the loop\n",
    "        if image_count >= 30:  # Check if 30 images have been captured\n",
    "            break  # Break out of the loop\n",
    "    cap.release()  # Release the webcam\n",
    "    cv2.destroyAllWindows()  # Close any open windows\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)  # Initialize the webcam\n",
    "\n",
    "# Load pre-trained face detection cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')  # Load the pre-trained face detection classifier\n",
    "\n",
    "# Check if attendance.csv file exists, create a new one if it doesn't\n",
    "attendance_csv_file = 'attendanceensemble.csv'\n",
    "if not os.path.exists(attendance_csv_file):  # Check if the attendance file exists\n",
    "    attendance_data = pd.DataFrame(columns=['Name', 'Time'])  # Create a new DataFrame with columns 'Name' and 'Time'\n",
    "    attendance_data.to_csv(attendance_csv_file, index=False)  # Save the attendance data to a CSV file\n",
    "else:\n",
    "    attendance_data = pd.read_csv(attendance_csv_file)  # Load the attendance data from the file\n",
    "\n",
    "quit_program = False\n",
    "while not quit_program:\n",
    "    option = input(\"Choose an option: 1 - Register a new face, 2 - Mark attendance, 3 - Quit: \")  # Prompt the user to choose an option\n",
    "    if option == '1':\n",
    "        register_face()  # Call the register_face function\n",
    "    elif option == '2':\n",
    "        ret, frame = cap.read()  # Read a frame from the webcam\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert the frame to grayscale\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))  # Detect faces in the frame\n",
    "        for (x, y, w, h) in faces:  # Iterate over the detected faces\n",
    "            face = gray[y:y+h, x:x+w]  # Extract the face region\n",
    "            face = cv2.resize(face, (128, 128))  # Resize the face image to 128x128 pixels\n",
    "            face = np.reshape(face, (1, 128, 128, 1)) / 255.0  # Reshape and normalize the face image for the CNN input\n",
    "\n",
    "            # CNN prediction\n",
    "            cnn_prediction = model.predict(face)  # Make a prediction using the CNN model\n",
    "            cnn_person_index = np.argmax(cnn_prediction)  # Get the index of the predicted class\n",
    "            cnn_confidence = np.max(cnn_prediction)  # Get the confidence score of the prediction\n",
    "\n",
    "            # SVM prediction\n",
    "            svm_face_flat = face.reshape(1, -1)\n",
    "            svm_prediction = svm_model.predict_proba(svm_face_flat)[0]  # Get probabilities for each class\n",
    "            svm_prediction_full = np.zeros(len(label_names))  # Initialize array to store SVM predictions\n",
    "            svm_prediction_full[svm_model.classes_] = svm_prediction  # Fill in SVM predictions for known classes\n",
    "\n",
    "            # Combine predictions\n",
    "            ensemble_prediction = (cnn_prediction[0] + svm_prediction_full) / 2  # Average the predictions\n",
    "            ensemble_person_index = np.argmax(ensemble_prediction)\n",
    "            ensemble_confidence = np.max(ensemble_prediction)\n",
    "\n",
    "            # Threshold for confidence\n",
    "            threshold = 0.7\n",
    "\n",
    "            if ensemble_confidence > threshold:  # Check if the confidence score is above a threshold\n",
    "                ensemble_name = label_names[ensemble_person_index]  # Get the name of the predicted person\n",
    "                # Check if the person is already in attendance\n",
    "                if not attendance_data[(attendance_data['Name'] == ensemble_name)].empty:\n",
    "                    print(\"Attendance already marked for:\", ensemble_name)\n",
    "                else:\n",
    "                    attendance_data = attendance_data.append({'Name': ensemble_name, 'Time': datetime.now()}, ignore_index=True)  # Add the attendance record to the DataFrame\n",
    "                    print(\"Attendance marked for (Ensemble):\", ensemble_name)  # Print the name for whom attendance was marked\n",
    "            else:\n",
    "                print(\"Unknown face detected.\")  # Print a message for an unknown face\n",
    "    elif option == '3':\n",
    "        quit_program = True  # Set the flag to quit the program\n",
    "    else:\n",
    "        print(\"Invalid option. Please choose again.\")  # Print an error message for an invalid option\n",
    "\n",
    "# Save attendance data to CSV\n",
    "attendance_data.to_csv(attendance_csv_file, index=False)  # Save the attendance data to a CSV file\n",
    "\n",
    "cap.release()  # Release the webcam\n",
    "cv2.destroyAllWindows()  # Close any open windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd03694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 94ms/step - loss: 0.7188 - accuracy: 0.9500\n",
      "CNN Model Accuracy: 0.949999988079071\n",
      "SVM Model Accuracy: 0.9333333333333333\n",
      "Ensemble Model Accuracy: 0.9416666607062022\n"
     ]
    }
   ],
   "source": [
    "# Evaluate CNN model on test data\n",
    "cnn_loss, cnn_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"CNN Model Accuracy:\", cnn_accuracy)\n",
    "\n",
    "# Evaluate SVM model on test data\n",
    "svm_accuracy = svm_model.score(X_test_flat, y_test)\n",
    "print(\"SVM Model Accuracy:\", svm_accuracy)\n",
    "\n",
    "# Calculate and print ensemble accuracy (average of CNN and SVM)\n",
    "ensemble_accuracy = (cnn_accuracy + svm_accuracy) / 2\n",
    "print(\"Ensemble Model Accuracy:\", ensemble_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07f660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
