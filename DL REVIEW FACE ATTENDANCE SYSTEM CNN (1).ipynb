{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e70efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 5s 565ms/step - loss: 2.5669 - accuracy: 0.3080 - val_loss: 1.7831 - val_accuracy: 0.6333\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 4s 458ms/step - loss: 1.3655 - accuracy: 0.7806 - val_loss: 0.7984 - val_accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 4s 467ms/step - loss: 0.7387 - accuracy: 0.8776 - val_loss: 0.5319 - val_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 4s 465ms/step - loss: 0.4732 - accuracy: 0.8819 - val_loss: 0.5132 - val_accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 4s 480ms/step - loss: 0.3338 - accuracy: 0.9325 - val_loss: 0.4660 - val_accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 4s 485ms/step - loss: 0.2416 - accuracy: 0.9367 - val_loss: 0.5655 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 4s 448ms/step - loss: 0.1558 - accuracy: 0.9620 - val_loss: 0.5862 - val_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 4s 511ms/step - loss: 0.1093 - accuracy: 0.9831 - val_loss: 0.6691 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 4s 489ms/step - loss: 0.0617 - accuracy: 0.9916 - val_loss: 0.9297 - val_accuracy: 0.9333\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 4s 489ms/step - loss: 0.0395 - accuracy: 0.9916 - val_loss: 1.0245 - val_accuracy: 0.9333\n",
      "Choose an option: 1 - Register a new face, 2 - Mark attendance, 3 - Quit: 2\n",
      "1/1 [==============================] - 0s 110ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Narthana\\AppData\\Local\\Temp\\ipykernel_6428\\4102362560.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  attendance_data = attendance_data.append({'Name': name, 'Time': datetime.now()}, ignore_index=True)  # Add the attendance record to the DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance marked for: narthana\n",
      "Choose an option: 1 - Register a new face, 2 - Mark attendance, 3 - Quit: 3\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import cv2  # OpenCV library for computer vision tasks\n",
    "import numpy as np  # NumPy library for numerical operations\n",
    "import os  # OS library for interacting with the operating system\n",
    "import pandas as pd  # Pandas library for data manipulation and analysis\n",
    "from datetime import datetime  # datetime module for working with dates and times\n",
    "from sklearn.model_selection import train_test_split  # Function for splitting data into training and testing sets\n",
    "from tensorflow.keras.models import Sequential  # Keras Sequential model for building neural networks\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense  # Keras layers for building convolutional neural networks\n",
    "\n",
    "# Function to load images and labels from dataset folder\n",
    "def load_dataset(dataset_path):\n",
    "    images = []  # List to store images\n",
    "    labels = []  # List to store labels\n",
    "    label_names = {}  # Dictionary to store label names\n",
    "\n",
    "    for label, name in enumerate(os.listdir(dataset_path)):  # Iterate over folders in the dataset path\n",
    "        label_names[label] = name  # Store label name in the dictionary\n",
    "        for image_name in os.listdir(os.path.join(dataset_path, name)):  # Iterate over images in each folder\n",
    "            image = cv2.imread(os.path.join(dataset_path, name, image_name), cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "            if image is not None:  # Check if the image was loaded successfully\n",
    "                image = cv2.resize(image, (128, 128))  # Resize the image to 128x128 pixels\n",
    "                images.append(image)  # Add the image to the list\n",
    "                labels.append(label)  # Add the label to the list\n",
    "\n",
    "    return np.array(images), np.array(labels), label_names  # Return images, labels, and label names\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"C:\\\\Users\\\\Narthana\\\\Downloads\\\\images\"  # Path to the dataset folder\n",
    "images, labels, label_names = load_dataset(dataset_path)  # Load the dataset\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)  # Split data into training and testing sets\n",
    "\n",
    "# Reshape images\n",
    "X_train = X_train.reshape(-1, 128, 128, 1)  # Reshape training images for CNN input\n",
    "X_test = X_test.reshape(-1, 128, 128, 1)  # Reshape testing images for CNN input\n",
    "\n",
    "# Normalize images\n",
    "X_train = X_train / 255.0  # Normalize training images to [0, 1] range\n",
    "X_test = X_test / 255.0  # Normalize testing images to [0, 1] range\n",
    "\n",
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),  # Convolutional layer with 32 filters and 3x3 kernel\n",
    "    MaxPooling2D(2, 2),  # Max pooling layer with 2x2 pool size\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # Convolutional layer with 64 filters and 3x3 kernel\n",
    "    MaxPooling2D(2, 2),  # Max pooling layer with 2x2 pool size\n",
    "    Flatten(),  # Flatten layer to convert 2D feature maps to 1D feature vector\n",
    "    Dense(128, activation='relu'),  # Fully connected layer with 128 units and ReLU activation\n",
    "    Dense(len(label_names), activation='softmax')  # Output layer with units equal to the number of classes and softmax activation\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile the model with optimizers and loss function\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))  # Train the model on the training data and validate on the testing data\n",
    "\n",
    "# Function to register new faces\n",
    "def register_face():\n",
    "    name = input(\"Enter name to register: \")  # Prompt the user to enter a name\n",
    "    if not os.path.exists(os.path.join(dataset_path, name)):  # Check if the folder for the name exists\n",
    "        os.makedirs(os.path.join(dataset_path, name))  # Create a new folder for the name\n",
    "    cap = cv2.VideoCapture(0)  # Initialize the webcam\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')  # Load the pre-trained face detection classifier\n",
    "    image_count = 0  # Initialize the image count\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Read a frame from the webcam\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert the frame to grayscale\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))  # Detect faces in the frame\n",
    "        for (x, y, w, h) in faces:  # Iterate over the detected faces\n",
    "            image_count += 1  # Increment the image count\n",
    "            cv2.imwrite(os.path.join(dataset_path, name, f\"{name}_{image_count}.jpg\"), gray[y:y+h, x:x+w])  # Save the face image with the name and count\n",
    "            print(f\"Image {image_count} captured.\")  # Print a message indicating the image capture\n",
    "            if image_count >= 30:  # Check if 30 images have been captured\n",
    "                print(\"Registration successful!\")  # Print a success message\n",
    "                break  # Break out of the loop\n",
    "        if image_count >= 30:  # Check if 30 images have been captured\n",
    "            break  # Break out of the loop\n",
    "    cap.release()  # Release the webcam\n",
    "    cv2.destroyAllWindows()  # Close any open windows\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)  # Initialize the webcam\n",
    "\n",
    "# Load pre-trained face detection cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')  # Load the pre-trained face detection classifier\n",
    "\n",
    "# Check if attendance.csv file exists, create a new one if it doesn't\n",
    "if os.path.exists('attendance.csv'):  # Check if the attendance file exists\n",
    "    attendance_data = pd.read_csv('attendance.csv')  # Load the attendance data from the file\n",
    "else:\n",
    "    attendance_data = pd.DataFrame(columns=['Name', 'Time'])  # Create a new DataFrame with columns 'Name' and 'Time'\n",
    "\n",
    "quit_program = False\n",
    "while not quit_program:\n",
    "    option = input(\"Choose an option: 1 - Register a new face, 2 - Mark attendance, 3 - Quit: \")  # Prompt the user to choose an option\n",
    "    if option == '1':\n",
    "        register_face()  # Call the register_face function\n",
    "    elif option == '2':\n",
    "        ret, frame = cap.read()  # Read a frame from the webcam\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert the frame to grayscale\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))  # Detect faces in the frame\n",
    "        for (x, y, w, h) in faces:  # Iterate over the detected faces\n",
    "            face = gray[y:y+h, x:x+w]  # Extract the face region\n",
    "            face = cv2.resize(face, (128, 128))  # Resize the face image to 128x128 pixels\n",
    "            face = np.reshape(face, (1, 128, 128, 1)) / 255.0  # Reshape and normalize the face image for the CNN input\n",
    "            prediction = model.predict(face)  # Make a prediction using the CNN model\n",
    "            person_index = np.argmax(prediction)  # Get the index of the predicted class\n",
    "            confidence = np.max(prediction)  # Get the confidence score of the prediction\n",
    "            if confidence > 0.7:  # Check if the confidence score is above a threshold\n",
    "                name = label_names[person_index]  # Get the name of the predicted person\n",
    "                attendance_data = attendance_data.append({'Name': name, 'Time': datetime.now()}, ignore_index=True)  # Add the attendance record to the DataFrame\n",
    "                print(\"Attendance marked for:\", name)  # Print the name for whom attendance was marked\n",
    "            else:\n",
    "                print(\"Unknown face detected.\")  # Print a message for an unknown face\n",
    "    elif option == '3':\n",
    "        quit_program = True  # Set the flag to quit the program\n",
    "    else:\n",
    "        print(\"Invalid option. Please choose again.\")  # Print an error message for an invalid option\n",
    "\n",
    "# Save attendance data to CSV\n",
    "attendance_data.to_csv('attendance.csv', index=False)  # Save the attendance data to a CSV file\n",
    "\n",
    "cap.release()  # Release the webcam\n",
    "cv2.destroyAllWindows()  # Close any open windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25593af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 4s 511ms/step - loss: 0.0658 - accuracy: 0.9747 - val_loss: 0.8965 - val_accuracy: 0.9333\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 4s 475ms/step - loss: 0.0343 - accuracy: 0.9958 - val_loss: 0.8444 - val_accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 4s 451ms/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 0.9630 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 4s 455ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.0031 - val_accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 4s 451ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0336 - val_accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 4s 516ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0913 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 4s 537ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1572 - val_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 4s 515ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1886 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 4s 507ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2257 - val_accuracy: 0.9333\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 4s 496ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2943 - val_accuracy: 0.9333\n",
      "Final Validation Accuracy: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))  # Train the model on the training data and validate on the testing data\n",
    "\n",
    "# Get the final accuracy from the history\n",
    "final_accuracy = history.history['val_accuracy'][-1]\n",
    "print(\"Final Validation Accuracy:\", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22fc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
